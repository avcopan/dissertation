\chapter[%
    Algorithms for Linear-Response Density Cumulant Theory
]{%
    Algorithms for Linear-Response Density Cumulant Theory
}
\label{ch:davidson}

\begin{enumerate}
    \item
        \cref{ch:response} presents a new model for electronic excited states,
        which is based on a linear-response formulation of density cumulant
        theory.
    \item
        In this model, excitation energies and transition properties are
        computed as generalized eigenpairs of the DCT energy Hessian with
        respect to the parameters of the energy functional.
    \item
        Since number of parameters in the ODC-12 variant of density cumulant
        theory scales as
        \(
            \mathcal{O}(o^2v^2)
        \)
        with the number of occupied (\(o\)) and virtual (\(v\)) orbitals, the
        memory requirement for the Hessian matrix scales with the fourth power
        of \(o\) and \(v\), and the number of floating point operations needed
        to diagonalize it scales with the sixth power of these dimensions.
    \item
        Such an approach will rapidly overwhelm available computing resources
        even for relatively small molecules.
\end{enumerate}


\section{The Davidson Algorithm}
\begin{enumerate}
    \item
        For the study of valence and low-lying Rydberg states, the cost of the
        LR-ODC-12 method can be drastically reduced by the use of direct matrix
        algorithms, such as the Davidson
        algorithm.\cite{Liu:1978p49,Davidson:1975p87}
    \item
        Direct algorithms represent a linear transformation as a function
        \(
            \mathbf{L}(\cdot)
        \)
        mapping vectors in its domain to vectors in its codomain, rather than as
        an array of coefficients
        \(
            \mathbf{L}
            =
            [L_{ij}]
        \)
        over a complete basis.
    \item
        That is, the result of the transformation is determined {\itshape
        directly} without forming its matrix representation in computer memory.
    \item
        The Davidson algorithm applies this technique in the context of a matrix
        diagonalization, by progressively growing a basis
        \(
            \{\mathbf{u}_1, \ldots,\mathbf{u}_d\}
        \)
        to span the lowest or highest eigenvectors of a matrix to some threshold
        of accuracy.
    \item
        In the context of LR-ODC-12, this allows us to reduce our computational
        effort to \(\mathcal{O}(o^2v^4d)\) and our memory requirement to
        \(\mathcal{O}(o^2v^2d)\), where \(d\) is typically on the order of ten
        times the desired number of eigenvalues.
\end{enumerate}


\section{The LR-ODC-12 Eigenvalue Equation}


\section{Algorithms}
\label{sec:algorithms}

\begin{algorithm}
    \caption{%
        Canonical multiroot Davidson algorithm for a generalized non-symmetric
        eigenvalue problem,
        $\mathbf{L}\mathbf{v}_k=\lambda_k\mathbf{G}\mathbf{v}_k$, with periodic
        subspace collapse.
        Requires linear transformation functions and diagonal approximations
        (indicated by tildes) for \(\mathbf{L}\) and \(\mathbf{G}\)
        and solves for the lowest \(n\) eigenvalues and eigenvectors.
    }
    \label{algo:davidson}
    \begin{algorithmic}[1]
        \Procedure{Davidson}{%
            $
            \mathbf{L}(\cdot),
            \mathbf{G}(\cdot),
            \tilde{\mathbf{L}},
            \tilde{\mathbf{G}},
            \mathbf{U}^{(0)},
            n,
            d_\mathrm{max},
            i_\mathrm{max},
            r_\mathrm{tol}
            $%
        }
        \State
        Initialize the expansion space with a set of guess vectors,
        \(\mathbf{U}\leftarrow\mathbf{U}^{(0)}\).
        \For{$1\leq i\leq i_\mathrm{max}$}{}
            \State
            Construct subspace representation and solve the lowest \(n\)
            eigenvalues.
            \[
                \mathbf{L}^\mathrm{sub}
                =
                \mathbf{U}^\dagger
                \mathbf{L}(\mathbf{U})
            \]
            \[
                \mathbf{G}^\mathrm{sub}
                =
                \mathbf{U}^\dagger
                \mathbf{G}(\mathbf{U})
            \]
            \[
                \mathbf{L}^\mathrm{sub}
                \mathbf{v}_k^\mathrm{sub}
                =
                \lambda_k
                \mathbf{G}^\mathrm{sub}
                \mathbf{v}_k^\mathrm{sub}
            \]
            \State
            Calculate the eigenvector residuals over the full space.
            \[
                \mathbf{r}_k
                =
                (
                    \mathbf{L}(\mathbf{U})
                    -
                    \lambda_k
                    \mathbf{G}(\mathbf{U})
                )
                \mathbf{v}_k^\mathrm{sub}
            \]
            \If{$\max(\mathbf{r}_k) < r_\mathrm{tol}$ for all $k$}
                \State
                Set
                \(\mathbf{v}_k\leftarrow\mathbf{U}\mathbf{v}_k^\mathrm{sub}\)
                and quit the loop.  The eigenvectors are converged.
            \EndIf
            \State
            Determine new direction vectors by a quasi-Newton-Raphson step.
            \[
                \mathbf{d}_k^{(i)}
                =
                -
                (
                    \tilde{\mathbf{L}}
                    -
                    \lambda_k
                    \tilde{\mathbf{G}}
                )^{-1}
                \mathbf{r}_k
            \]
            \State
            Project out the span of \(\mathbf{U}\) and orthogonalize via
            SVD compression.
            \[
                \widehat{\mathbf{U}}^{(i)}
                =
                (\mathbf{1} - \mathbf{U}^\dagger \mathbf{U})
                \mathbf{D}^{(i)}
            \]
            \[
                \widehat{\mathbf{U}}^{(i)}
                \approx
                \mathbf{U}^{(i)}
                \mathbf{\Sigma}^{(i)}
                \mathbf{W}^{(i)\dagger}
            \]
            \If{%
                $
                \mathrm{rank}(\mathbf{U})
                +
                \mathrm{rank}(\mathbf{U}^{(i)})
                <
                d_\mathrm{max}
                $%
            }
                \State
                Extend the expansion space,
                \(
                    \mathbf{U}
                    \leftarrow
                    (\mathbf{U}\ \mathbf{U}^{(i)})
                \)
            \Else
                \State
                Collapse the expansion space,
                \(
                    \mathbf{U}
                    \leftarrow
                    (
                        \mathbf{U}
                        \mathbf{v}_1^\mathrm{sub}\ 
                        \cdots\ 
                        \mathbf{U}
                        \mathbf{v}_n^\mathrm{sub}
                    )
                \).
            \EndIf
        \EndFor
        \State
        {\bfseries return}
        \(
            \lambda_k,
            \mathbf{v}_k
        \)
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

The LR-ODC-12 eigenvalue equation has a two-by-two block structure which
describes the independent variation of the state parameters and their complex
conjugates.
\begin{equation}
    \label{eq:linear-response-eigenvalue-equation}
    \mathbf{E}(\mathbf{z}_k)
    =
    \omega_k
    \mathbf{M}(\mathbf{z}_k)
    ,
    \quad
    \mathbf{E}
    =
    \begin{pmatrix}
        \mathbf{A} & \mathbf{B} \\
        \mathbf{B}^* & \mathbf{A}^*
    \end{pmatrix}
    ,
    \quad
    \mathbf{M}
    =
    \begin{pmatrix}
        \mathbf{S} & \mathbf{0} \\
        \mathbf{0} & -\mathbf{S}^*
    \end{pmatrix}
    ,
    \quad
    \mathbf{z}_k
    =
    \begin{pmatrix}
        \mathbf{x}_k \\
        \mathbf{y}_k
    \end{pmatrix}
\end{equation}
This block symmetry leads to a paired system of eigenvalues,
\(
    \omega_{\pm k}
    =
    \pm\omega_k
\).
The submatrices in \cref{eq:linear-response-eigenvalue-equation} are further
blocked according to whether they describe variations with respect to one-body
(\(\mathbf{t}_1\)) or two-body (\(\mathbf{t}_2\)) parameters.
\begin{equation}
    \label{eq:conjugate-blocks}
    \mathbf{A}
    =
    \begin{pmatrix}
        \mathbf{A}_{11} & \mathbf{A}_{12} \\
        \mathbf{A}_{21} & \mathbf{A}_{22} \\
    \end{pmatrix}
    \quad
    \mathbf{B}
    =
    \begin{pmatrix}
        \mathbf{B}_{11} & \mathbf{B}_{12} \\
        \mathbf{B}_{21} & \mathbf{B}_{22} \\
    \end{pmatrix}
    \quad
    \mathbf{S}
    =
    \begin{pmatrix}
        \mathbf{S}_{11} & \mathbf{0} \\
        \mathbf{0} & \mathbf{1}_2 \\
    \end{pmatrix}
    \quad
    \mathbf{x}_k
    =
    \begin{pmatrix}
        \mathbf{x}_{k,1} \\
        \mathbf{x}_{k,2}
    \end{pmatrix}
\end{equation}
The dimensions of the diagonal two-body blocks (\(\mathbf{A}_{22}\) and
\(\mathbf{B}_{22}\) and \(\mathbf{1}_s\)) in these matrices scale as
\((\mathrm{o}^2\mathrm{v}^2)^2\) with the number of occupied (\(\mathrm{o}\))
and virtual (\(\mathrm{v}\)) orbitals, rapidly overwhelming the storage space on
a given computer as the number of electrons and basis functions increases.
This problem can be circumvented by using so-called ``direct'' matrix
algorithms, which avoid the explicit representation of a matrix as an array of
coefficients \(\mathbf{L}=[L_{\mu\nu}]\) by instead defining a function
\(\mathbf{L}(\mathbf{U})\) which returns the output of the linear transformation
on an arbitrary set of vectors \(\mathbf{U}=(\mathbf{u}_1\ \cdots\
\mathbf{u}_m)\).
The standard direct algorithm for extremal eigenvalues of large,
diagonally-dominant matrices is the Davidson
algorithm,\cite{Davidson:1975p87,Liu:1978p49} which solves the eigenvalue
problem by progressively growing an expansion space for the \(n\) lowest (or
highest) generalized eigenvectors.
The procedure is described in \Cref{algo:davidson}.

The full set of linear transformation formulas for the LR-ODC-12 Hessian and
metric blocks is given in the appendix
(\cref{sec:linear-transformation-formulas}), but let us consider the diagonal
two-body Hessian as an example.
The image of an arbitrary two-body vector
\(
    \mathbf{u}_{\mu,2}
    =
    [u_{\mu,ab}^{ij}]
\)
under this transformation is given by
\begin{equation}
    \label{eq:two-body-hessian-function-in-text}
    \begin{array}{r@{\,}l}
        (\mathbf{A}_{22}(\mathbf{u}_{\mu,2}))_{ijab}
        =
        &
        -
        P_{(a/b)}
        \mathcal{F}_a^c
        u_{\mu,cb}^{ij}
        -
        P^{(i/j)}
        \mathcal{F}_k^i
        u_{\mu,ab}^{kj}
        +
        \tfrac{1}{2}
        \overline{g}_{ab}^{cd}
        u_{\mu,cd}^{ij}
        +
        \tfrac{1}{2}
        \overline{g}_{kl}^{ij}
        u_{\mu,ab}^{kl}
        \\[5pt]
        &
        -
        P_{(a/b)}^{(i/j)}
        \overline{g}_{la}^{jc}
        u_{\mu,cb}^{il}
        +
        \tfrac{1}{2}
        P_{(a/b)}
        \mathcal{G}_{af}^{ec}
        t_{eb}^{ij}
        t_{kl}^{fd*}
        u_{\mu,cd}^{kl}
        +
        \tfrac{1}{2}
        P_{(a/b)}
        \mathcal{G}_{ka}^{me}
        t_{eb}^{ij}
        t_{ml}^{cd*}
        u_{\mu,cd}^{kl}
        \\[5pt]
        &
        +
        \tfrac{1}{2}
        P^{(i/j)}
        \mathcal{G}_{me}^{ic}
        t_{ab}^{mj}
        t_{kl}^{ed*}
        u_{\mu,cd}^{kl}
        +
        \tfrac{1}{2}
        P^{(i/j)}
        \mathcal{G}_{mk}^{in}
        t_{ab}^{mj}
        t_{nl}^{cd*}
        u_{\mu,cd}^{kl}
    \end{array}
\end{equation}
where the \(i,j,k,l,\ldots\) run over occupied spin-orbitals, \(a,b,c,d,\ldots\)
run over virtual (un-occupied) spin-orbitals, and summation over repeated
indices is implied.
The important thing to note is that we need only two \(\mathrm{v}^4\)-sized
intermediates (\(\overline{g}_{ab}^{cd}\) and \(\mathcal{G}_{ab}^{cd}\)) to
define our linear transformations, and that the image of the two-body Hessian
only has \(\mathcal{O}(d_\mu\mathrm{o}^2\mathrm{v}^2)\) elements where \(d_\mu\)
is the dimension of the \(\mu\) index.
In general the Davidson algorithm requires no more than 10-20 subspace vectors
per root, sometimes as few as 2 or 3, so that even for small systems it is easy
to satisfy \( d_\mu \ll \mathrm{o}^2\mathrm{v}^2 \), resulting in substantial
memory savings.
\Cref{eq:two-body-hessian-function-in-text} also includes the timing bottleneck
for the LR-ODC-12, the contraction of the \(\mathrm{v}^4\) integrals with the
expansion vector, \(\mathrm{g}_{ab}^{cd}u_{\mu,cd}^{ij}\), which scales as
\(\mathcal{O}(d_\mu\mathrm{o}^2\mathrm{v}^4)\) in the number of floating point
operations.
This term is the rate limiting step in EOM-CCSD as well.

A direct application of \cref{algo:davidson} to
\cref{eq:linear-response-eigenvalue-equation} is complicated by the fact that
the desired (small, positive) eigenvalues are in the middle of the spectrum,
rather than at the extremes.
We make use of two strategies.

\paragraph{Strategy 1}
One approach is to invert the eigenvalue equation, solving for the {\itshape
largest} positive inverse eigenvalues, which is easily done by selecting the
highest rather than the lowest roots at each step in \cref{algo:davidson}.
\begin{equation}
    \mathbf{M}(\mathbf{z}_k)
    =
    \omega_k^{-1}
    \mathbf{E}(\mathbf{z}_k)
\end{equation}
This has the added advantage that the energy Hessian \(\mathbf{E}\) is generally
positive definite, which allows us to treat the subspace diagonalizations as
standard Hermitian eigenvalue equation with real eigenvalues and orthonormal
eigenvectors.
A simple, effective choice of guess vectors in this approach is to determine the
lowest eigenvectors of the following diagonal approximation to
\cref{eq:two-body-hessian-function-in-text}
\begin{equation}
    (\tilde{\mathbf{A}}_{22}(\mathbf{u}_{\mu}))_{ijab}
    \equiv
    -
    (
        \mathcal{F}_i^i
        +
        \mathcal{F}_j^j
        +
        \mathcal{F}_a^a
        +
        \mathcal{F}_b^b
    )
    u_{\mu,ab}^{ij}
\end{equation}
which are simply the standard unit vectors associated with the smallest diagonal
entries.
The virtual coefficients \(\mathcal{F}_a^a,\mathcal{F}_b^b\) in this equation
are generally negative, so this has the form of an orbital energy difference
like we see in Hartree-Fock theory.
For larger systems, we manage the memory requirements of the method by keeping
successive groups of expansion vectors and images,
\(
    \mathbf{U}^{(i)},
    \mathbf{E}(\mathbf{U}^{(i)}),
    \mathbf{M}(\mathbf{U}^{(i)})
\),
on disk and reading them in as needed.
These can be further subdivided into even smaller blocks if needed.


\paragraph{Strategy 2}
Assuming real matrices, we can add and subtract the block rows of
\cref{eq:linear-response-eigenvalue-equation} to arrive at the following pair of
equations.
\begin{equation}
    \label{eq:a-plus-b}
    (\mathbf{A} + \mathbf{B})
    (\mathbf{x}_k + \mathbf{y}_k)
    =
    \omega_k
    \mathbf{S}
    (\mathbf{x}_k - \mathbf{y}_k)
\end{equation}
\begin{equation}
    \label{eq:a-minus-b}
    (\mathbf{A} - \mathbf{B})
    (\mathbf{x}_k - \mathbf{y}_k)
    =
    \omega_k
    \mathbf{S}
    (\mathbf{x}_k + \mathbf{y}_k)
\end{equation}
Multiplying both equations by \(\mathbf{S}^{-1}\), we can write them as follows
\begin{equation}
    \mathbf{H}^+(\mathbf{c}_k^+)
    =
    \omega_k
    \mathbf{c}_k^-
\end{equation}
\begin{equation}
    \mathbf{H}^-(\mathbf{c}_k^-)
    =
    \omega_k
    \mathbf{c}_k^+
\end{equation}
where we have defined the following intermediates
\begin{equation}
    \mathbf{H}^{\pm}
    \equiv
    \mathbf{S}^{-1}
    (\mathbf{A} \pm \mathbf{B})
\end{equation}
\begin{equation}
    \mathbf{c}_k^{\pm}
    \equiv
    \mathbf{x}_k \pm \mathbf{y}_k
\end{equation}
This provides a reduced eigenvalue equation for the squared excitations energies
\begin{equation}
    \overline{\mathbf{H}}(\mathbf{c}_k^+)
    =
    \omega_k^2
    \mathbf{c}_k^+
\end{equation}
\begin{equation}
    \overline{\mathbf{H}}
    =
    \mathbf{H}^-
    \mathbf{H}^+
\end{equation}
The blocks of the generalized eigenvector can then be recovered as follows
\begin{equation}
    \mathbf{x}_k
    =
    \tfrac{1}{2}
    (
        \mathbf{c}_k^+
        +
        \omega_k^{-1}
        \mathbf{H}^+(\mathbf{c}_k^+)
    )
\end{equation}
\begin{equation}
    \mathbf{y}_k
    =
    \tfrac{1}{2}
    (
        \mathbf{c}_k^+
        -
        \omega_k^{-1}
        \mathbf{H}^+(\mathbf{c}_k^+)
    )
\end{equation}

Which also shows that any formula can be reduced to a formula for the reduced
eigenvalues and eigenvectors.
For example, assuming real integral arrays (\(\mathbf{p}^*=\mathbf{p}\))
\begin{equation}
    \mathbf{z}_k^\dagger
    \mathbf{v}'
    =
    \mathbf{c}_k^{+\dagger}
    \mathbf{p}
\end{equation}
and
\begin{equation}
    \mathbf{z}_k^\dagger
    \mathbf{M}
    \mathbf{z}_k
    =
    \mathbf{c}_k^{+\dagger}
    \mathbf{S}
    \mathbf{c}_k^{-}
    =
    \omega_k^{-1}
    \mathbf{c}_k^{+\dagger}
    \mathbf{S}
    \mathbf{H}^+
    \mathbf{c}_k^+
\end{equation}
\begin{equation}
    \lim_{\omega\rightarrow \omega_k}
    (\omega-\omega_k)
    \langle\!\langle \hat{V}; \hat{V} \rangle\!\rangle_\omega
    =
    \frac{%
        \omega_k
        |\mathbf{c}_k^{+\dagger} \mathbf{p}|^2
    }{% 
        \mathbf{c}_k^{+\dagger} 
        (\mathbf{A} + \mathbf{B})
        \mathbf{c}_k^+
    }
\end{equation}


From \cref{eq:conjugate-blocks} we can see that computing the inverse of
\(\mathbf{S}\) requires us to invert the orbital block of the metric.
This matrix is given by
\begin{equation}
    (\mathbf{S}_{11})_{ia,jb}
    =
    \gamma^i_j
    \delta_a^b
    -
    \delta_j^i
    \gamma^b_a
\end{equation}
where
\(
    \gamma_j^i
\)
and
\(
    \gamma_a^b
\)
are occupied and virtual blocks of the one-body density matrix.
By expanding these matrices in the natural spin-orbital basis (indicated by
prime indices) where the one-body density matrix is diagonal
\begin{equation}
    \gamma_j^i
    =
    (\mathbf{Y})_j^{j'}
    (\mathbf{Y}^\dagger)_{i'}^i
    \delta_{j'}^{i'}
    \gamma_{j'}
    \qquad
    \gamma_a^b
    =
    (\mathbf{Y})_a^{a'}
    (\mathbf{Y}^\dagger)_{b'}^b
    \delta_{a'}^{b'}
    \gamma_{a'}
\end{equation}
we can derive the following simple and inexpensive formula for the inverse of
the orbital metric.
\begin{equation}
    (\mathbf{S}_{11}^{-1})_{ia,jb}
    =
    \frac{%
        (\mathbf{Y}^\dagger)_{j'}^i
        (\mathbf{Y})_a^{b'}
    }{%
        \gamma_{j'}-\gamma_{b'}
    }
    (\mathbf{Y}^\dagger)_{b'}^b
    (\mathbf{Y})_j^{j'}
\end{equation}
The appropriate diagonal approximation to \(\mathbf{H}\) can simply be computed
as the square of \(\tilde{\mathbf{A}}\), since in low order we have
\(\mathbf{B}\approx\mathbf{0}\) and \(\mathbf{S}\approx\mathbf{1}\)


\begin{equation}
    \mathbf{H}^\dagger
    (\mathbf{S}(\mathbf{x}_k - \mathbf{y}_k))
    =
    \omega_k^2
    (\mathbf{S}(\mathbf{x}_k - \mathbf{y}_k))
\end{equation}


\begin{subappendices}
\section{LR-ODC-12 Linear Transformation Formulas}
\label{sec:linear-transformation-formulas}

\begin{equation}
    \begin{array}{r@{\,}l}
        (\mathbf{A}_{11}(\mathbf{u}_{\mu,1}))_{ia}
        =
        &
        h_j^i
        \gamma_a^b
        u_{\mu,b}^j
        +
        h_a^b
        \gamma_j^i
        u_{\mu,b}^j
        -
        (\bar{\mathbf{F}})_j^i
        u_{\mu,a}^j
        -
        (\bar{\mathbf{F}})_a^b
        u_{\mu,b}^i
        +
        \overline{g}_{nj}^{mi}
        \gamma_{ma}^{nb}
        u_{\mu,b}^j
        \\[5pt]
        &
        +
        \overline{g}_{ma}^{nb}
        \gamma_{nj}^{mi}
        u_{\mu,b}^j
        +
        \overline{g}_{jf}^{ie}
        \gamma_{ae}^{bf}
        u_{\mu,b}^j
        +
        \overline{g}_{ae}^{bf}
        \gamma_{jf}^{ie}
        u_{\mu,b}^j
        +
        \overline{g}_{me}^{ib}
        \gamma_{ja}^{me}
        u_{\mu,b}^j
        \\[5pt]
        &
        +
        \overline{g}_{ja}^{me}
        \gamma_{me}^{ib}
        u_{\mu,b}^j
    \end{array}
\end{equation}

\begin{equation}
    \begin{array}{r@{\,}l}
        (\mathbf{B}_{11}(\mathbf{u}_{\mu,1}))_{ia}
        =
        &
        \overline{g}_{be}^{im}
        \gamma_{ma}^{je}
        u_{\mu,j}^b
        +
        \overline{g}_{ma}^{je}
        \gamma_{be}^{im}
        u_{\mu,j}^b
        +
        \overline{g}_{mb}^{ie}
        \gamma_{ae}^{jm}
        u_{\mu,j}^b
        +
        \overline{g}_{ae}^{jm}
        \gamma_{mb}^{ie}
        u_{\mu,j}^b
        \\[5pt]
        &
        +
        \tfrac{1}{2}
        \overline{g}_{mn}^{ij}
        \gamma_{ab}^{mn}
        u_{\mu,j}^b
        +
        \tfrac{1}{2}
        \overline{g}_{ab}^{mn}
        \gamma_{mn}^{ij}
        u_{\mu,j}^b
        +
        \tfrac{1}{2}
        \overline{g}_{ef}^{ij}
        \gamma_{ab}^{ef}
        u_{\mu,j}^b
        +
        \tfrac{1}{2}
        \overline{g}_{ab}^{ef}
        \gamma_{ef}^{ij}
        u_{\mu,j}^b
    \end{array}
\end{equation}

\begin{equation}
    \begin{array}{r@{\,}l}
        (\mathbf{A}_{22}(\mathbf{u}_{\mu,2}))_{ijab}
        =
        &
        -
        P_{(a/b)}
        \mathcal{F}_a^c
        u_{\mu,cb}^{ij}
        -
        P^{(i/j)}
        \mathcal{F}_k^i
        u_{\mu,ab}^{kj}
        +
        \tfrac{1}{2}
        \overline{g}_{ab}^{cd}
        u_{\mu,cd}^{ij}
        +
        \tfrac{1}{2}
        \overline{g}_{kl}^{ij}
        u_{\mu,ab}^{kl}
        \\[5pt]
        &
        -
        P_{(a/b)}^{(i/j)}
        \overline{g}_{la}^{jc}
        u_{\mu,cb}^{il}
        +
        \tfrac{1}{2}
        P_{(a/b)}
        \mathcal{G}_{af}^{ec}
        t_{eb}^{ij}
        t_{kl}^{fd*}
        u_{\mu,cd}^{kl}
        +
        \tfrac{1}{2}
        P_{(a/b)}
        \mathcal{G}_{ka}^{me}
        t_{eb}^{ij}
        t_{ml}^{cd*}
        u_{\mu,cd}^{kl}
        \\[5pt]
        &
        +
        \tfrac{1}{2}
        P^{(i/j)}
        \mathcal{G}_{me}^{ic}
        t_{ab}^{mj}
        t_{kl}^{ed*}
        u_{\mu,cd}^{kl}
        +
        \tfrac{1}{2}
        P^{(i/j)}
        \mathcal{G}_{mk}^{in}
        t_{ab}^{mj}
        t_{nl}^{cd*}
        u_{\mu,cd}^{kl}
    \end{array}
\end{equation}

\begin{equation}
    \begin{array}{r@{\,}l}
        (\mathbf{B}_{22}(\mathbf{u}_{\mu,2}))_{ijab}
        =
        &
        \tfrac{1}{2}
        P_{(a/b)}
        \mathcal{G}_{ac}^{ef}
        t_{eb}^{ij}
        t_{fd}^{kl}
        u_{\mu,kl}^{cd}
        +
        \tfrac{1}{2}
        P_{(a/b)}
        \mathcal{G}_{na}^{ke}
        t_{eb}^{ij}
        t_{cd}^{nl}
        u_{\mu,kl}^{cd}
        \\[5pt]
        &
        +
        \tfrac{1}{2}
        P^{(i/j)}
        \mathcal{G}_{mc}^{if}
        t_{ab}^{mj}
        t_{fd}^{kl}
        u_{\mu,kl}^{cd}
        +
        \tfrac{1}{2}
        P^{(i/j)}
        \mathcal{G}_{mn}^{ik}
        t_{ab}^{mj}
        t_{cd}^{nl}
        u_{\mu,kl}^{cd}
    \end{array}
\end{equation}

\begin{equation}
    \begin{array}{r@{\,}l}
        (\mathbf{A}_{12}(\mathbf{u}_{\mu,2}))_{ia}
        =
        &
        -
        \tfrac{1}{2}
        \overline{g}_{la}^{cd}
        u_{\mu,cd}^{il}
        -
        \tfrac{1}{2}
        \overline{g}_{kl}^{id}
        u_{\mu,ad}^{kl}
        -
        \tfrac{1}{2}
        (\mathcal{I}_a^i)_k^m
        t_{ml}^{cd*}
        u_{\mu,cd}^{kl}
        -
        \tfrac{1}{2}
        (\mathcal{I}_a^i)_e^c
        t_{kl}^{ed*}
        u_{\mu,cd}^{kl}
        \\[5pt]
        &
        -
        \overline{g}_{ae}^{mc}
        t_{ml}^{ed*}
        u_{\mu,cd}^{il}
        -
        \overline{g}_{ke}^{im}
        t_{ml}^{ed*}
        u_{\mu,ad}^{kl}
        -
        \tfrac{1}{4}
        \overline{g}_{la}^{mn}
        t_{mn}^{cd*}
        u_{\mu,cd}^{il}
        \\[5pt]
        &
        -
        \tfrac{1}{4}
        \overline{g}_{ef}^{id}
        t_{kl}^{ef*}
        u_{\mu,ad}^{kl}
    \end{array}
\end{equation}

\begin{equation}
    \begin{array}{r@{\,}l}
        (\mathbf{B}_{12}(\mathbf{u}_{\mu,2}))_{ia}
        =
        &
        -
        \tfrac{1}{2}
        (\mathcal{I}_a^i)_m^k
        t_{cd}^{ml}
        u_{\mu,kl}^{cd}
        -
        \tfrac{1}{2}
        (\mathcal{I}_a^i)_c^e
        t_{ed}^{kl}
        u_{\mu,kl}^{cd}
        -
        \overline{g}_{ad}^{le}
        t_{ce}^{ki}
        u_{\mu,kl}^{cd}
        -
        \overline{g}_{md}^{il}
        t_{ca}^{km}
        u_{\mu,kl}^{cd}
        \\[5pt]
        &
        -
        \tfrac{1}{4}
        \overline{g}_{ma}^{kl}
        t_{cd}^{im}
        u_{\mu,kl}^{cd}
        -
        \tfrac{1}{4}
        \overline{g}_{cd}^{ie}
        t_{ae}^{kl}
        u_{\mu,kl}^{cd}
    \end{array}
\end{equation}

\begin{equation}
    \begin{array}{r@{\,}l}
        (\mathbf{A}_{21}(\mathbf{u}_{\mu,1}))_{ijab}
        =
        &
        -
        P^{(i/j)}
        \overline{g}_{ab}^{jc}
        u_{\mu,c}^i
        -
        P_{(a/b)}
        \overline{g}_{kb}^{ij}
        u_{\mu,a}^k
        -
        P^{(i/j)}
        (\mathcal{I}_k^c)_m^i
        t_{ab}^{mj}
        u_{\mu,c}^k
        \\[5pt]
        &
        -
        P_{(a/b)}
        (\mathcal{I}_k^c)_a^e
        t_{eb}^{ij}
        u_{\mu,c}^k
        -
        P_{(a/b)}^{(i/j)}
        \overline{g}_{ma}^{ce}
        t_{eb}^{mj}
        u_{\mu,c}^i
        -
        P_{(a/b)}^{(i/j)}
        \overline{g}_{km}^{ie}
        t_{eb}^{mj}
        u_{\mu,a}^k
        \\[5pt]
        &
        -
        \tfrac{1}{2}
        P^{(i/j)}
        \overline{g}_{mn}^{jc}
        t_{ab}^{mn}
        u_{\mu,c}^i
        -
        \tfrac{1}{2}
        P_{(a/b)}
        \overline{g}_{kb}^{ef}
        t_{ef}^{ij}
        u_{\mu,a}^k
    \end{array}
\end{equation}

\begin{equation}
    \begin{array}{r@{\,}l}
        (\mathbf{B}_{21}(\mathbf{u}_{\mu,1}))_{ijab}
        =
        &
        -
        P^{(i/j)}
        (\mathcal{I}_c^k)_m^i
        t_{ab}^{mj}
        u_{\mu,k}^c
        -
        P_{(a/b)}
        (\mathcal{I}_c^k)_a^e
        t_{eb}^{ij}
        u_{\mu,k}^c
        -
        P_{(a/b)}^{(i/j)}
        \overline{g}_{cb}^{je}
        t_{ae}^{ik}
        u_{\mu,k}^c
        \\[5pt]
        &
        -
        P_{(a/b)}^{(i/j)}
        \overline{g}_{kj}^{mb}
        t_{ac}^{im}
        u_{\mu,k}^c
        -
        \overline{g}_{mc}^{ij}
        t_{ab}^{km}
        u_{\mu,k}^c
        -
        \overline{g}_{ab}^{ke}
        t_{ce}^{ij}
        u_{\mu,k}^c
    \end{array}
\end{equation}

\begin{equation}
    (\mathbf{S}_{11}(\mathbf{u}_{\mu,1}))_{ia}
    =
    \gamma^i_j
    u_{\mu,a}^j
    -
    \gamma^b_a
    u_{\mu,b}^i
\end{equation}

\begin{equation}
    (\mathbf{S}_{11}^{-1}(\mathbf{u}_{\mu,1}))_{ia}
    =
    \frac{%
        (\mathbf{Y}^\dagger)_{j'}^i
        (\mathbf{Y})_a^{b'}
    }{%
        \gamma_{j'}-\gamma_{b'}
    }
    (\mathbf{Y}^\dagger)_{b'}^b
    (\mathbf{Y})_j^{j'}
    u_{\mu,b}^j
\end{equation}

\begin{equation}
    (\mathbf{Y}^\dagger)_{q'}^q
    \gamma_q^p
    (\mathbf{Y})_p^{p'}
    =
    \delta_{q'}^{p'}
    \gamma_{q'}
\end{equation}

\begin{equation}
    \tilde{\mathbf{S}}_{11}
    \equiv
    \tilde{\mathbf{S}}_{11}^{-1}
    \equiv
    \mathbf{1}_1
\end{equation}

\begin{equation}
    (\tilde{\mathbf{A}}_{11})_{ia,ia}
    \equiv
    -
    f_i^i
    +
    f_a^a
\end{equation}

\begin{equation}
    (\tilde{\mathbf{A}}_{22})_{ijab,ijab}
    \equiv
    -
    \mathcal{F}_i^i
    -
    \mathcal{F}_j^j
    -
    \mathcal{F}_a^a
    -
    \mathcal{F}_b^b
\end{equation}

\end{subappendices}
